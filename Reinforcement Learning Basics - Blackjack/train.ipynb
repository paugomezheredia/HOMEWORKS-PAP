{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib.patches import Patch\n",
    "from tqdm import tqdm\n",
    "\n",
    "import gymnasium as gym\n",
    "\n",
    "from IPython import display as pythondisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "MODULE_FULL_PATH = '/workspaces/HOMEWORKS-PAP/Reinforcement Learning Basics - Blackjack' # Path de la carpeta del proyecto en donde se encuentre src\n",
    "sys.path.insert(1, MODULE_FULL_PATH)\n",
    "\n",
    "from source.env import blackjack_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = blackjack_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1\n",
      "Initial State: ((20, 7, 0), {})\n",
      "Action: Stick, Next State: (20, 7, 0), Reward: -1.0, Done: True\n",
      "Episode 1 finished with total reward: -1.0\n",
      "\n",
      "Episode 2\n",
      "Initial State: ((11, 10, 0), {})\n",
      "Action: Hit, Next State: (20, 10, 0), Reward: 0.0, Done: False\n",
      "Action: Hit, Next State: (30, 10, 0), Reward: -1.0, Done: True\n",
      "Episode 2 finished with total reward: -1.0\n",
      "\n",
      "Episode 3\n",
      "Initial State: ((12, 10, 0), {})\n",
      "Action: Stick, Next State: (12, 10, 0), Reward: -1.0, Done: True\n",
      "Episode 3 finished with total reward: -1.0\n",
      "\n",
      "Episode 4\n",
      "Initial State: ((16, 6, 0), {})\n",
      "Action: Stick, Next State: (16, 6, 0), Reward: 1.0, Done: True\n",
      "Episode 4 finished with total reward: 1.0\n",
      "\n",
      "Episode 5\n",
      "Initial State: ((13, 7, 0), {})\n",
      "Action: Hit, Next State: (23, 7, 0), Reward: -1.0, Done: True\n",
      "Episode 5 finished with total reward: -1.0\n",
      "\n",
      "Episode 6\n",
      "Initial State: ((7, 4, 0), {})\n",
      "Action: Hit, Next State: (17, 4, 0), Reward: 0.0, Done: False\n",
      "Action: Stick, Next State: (17, 4, 0), Reward: -1.0, Done: True\n",
      "Episode 6 finished with total reward: -1.0\n",
      "\n",
      "Episode 7\n",
      "Initial State: ((13, 9, 0), {})\n",
      "Action: Stick, Next State: (13, 9, 0), Reward: 1.0, Done: True\n",
      "Episode 7 finished with total reward: 1.0\n",
      "\n",
      "Episode 8\n",
      "Initial State: ((20, 9, 1), {})\n",
      "Action: Stick, Next State: (20, 9, 1), Reward: 1.0, Done: True\n",
      "Episode 8 finished with total reward: 1.0\n",
      "\n",
      "Episode 9\n",
      "Initial State: ((19, 10, 0), {})\n",
      "Action: Hit, Next State: (23, 10, 0), Reward: -1.0, Done: True\n",
      "Episode 9 finished with total reward: -1.0\n",
      "\n",
      "Episode 10\n",
      "Initial State: ((12, 10, 0), {})\n",
      "Action: Hit, Next State: (14, 10, 0), Reward: 0.0, Done: False\n",
      "Action: Hit, Next State: (18, 10, 0), Reward: 0.0, Done: False\n",
      "Action: Stick, Next State: (18, 10, 0), Reward: -1.0, Done: True\n",
      "Episode 10 finished with total reward: -1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Number of episodes to run\n",
    "num_episodes = 10\n",
    "env = gym.make('Blackjack-v1', natural=False, sab=False)\n",
    "\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    # Reset the environment and get the initial state\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "\n",
    "    print(f\"Episode {episode + 1}\")\n",
    "    print(\"Initial State:\", state)\n",
    "\n",
    "    while not done:\n",
    "        # Sample a random action (0 or 1)\n",
    "        action = env.action_space.sample()\n",
    "\n",
    "        # Take the action and observe the result\n",
    "        next_state, reward, done, truncated, info = env.step(action)\n",
    "\n",
    "        # Print the step details\n",
    "        print(f\"Action: {'Hit' if action == 1 else 'Stick'}, Next State: {next_state}, Reward: {reward}, Done: {done}\")\n",
    "\n",
    "        # Update the total reward\n",
    "        total_reward += reward\n",
    "\n",
    "        # Update the state\n",
    "        state = next_state\n",
    "\n",
    "    print(f\"Episode {episode + 1} finished with total reward: {total_reward}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
